"""
Veritas News Analyzer - Main Analysis Module
ĞĞ±'Ñ”Ğ´Ğ½ÑƒÑ” scraping, Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ñ‚Ğ° Ğ·Ğ²Ñ–Ñ‚Ğ½Ñ–ÑÑ‚ÑŒ
"""

from typing import Dict, List
import json
from datetime import datetime
import logging

# Ğ†Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ½Ğ°ÑˆĞ¸Ñ… Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ–Ğ²
try:
    from .scraper import NewsExtractor
    from .translator import MultilingualVeritasCore
except ImportError:
    # Ğ”Ğ»Ñ standalone Ğ·Ğ°Ğ¿ÑƒÑĞºÑƒ
    import sys
    sys.path.append('.')
    from scraper import NewsExtractor
    from translator import MultilingualVeritasCore

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NewsAnalyzer:
    """
    Ğ“Ğ¾Ğ»Ğ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ½Ğ¾Ğ²Ğ¸Ğ½ Ğ·Ğ° Veritas Protocol
    """
    
    def __init__(self, config: Dict = None):
        self.extractor = NewsExtractor()
        self.veritas = MultilingualVeritasCore(config=config)
        self.analysis_history: List[Dict] = []
        self.config = config or {}
    
    def analyze_url(self, url: str, save_history: bool = True) -> Dict:
        """
        ĞŸĞ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ½Ğ¾Ğ²Ğ¸Ğ½Ğ¸ Ğ· URL
        
        Args:
            url: URL Ğ½Ğ¾Ğ²Ğ¸Ğ½Ğ½Ğ¾Ñ— ÑÑ‚Ğ°Ñ‚Ñ‚Ñ–
            save_history: Ğ§Ğ¸ Ğ·Ğ±ĞµÑ€Ñ–Ğ³Ğ°Ñ‚Ğ¸ Ğ² Ñ–ÑÑ‚Ğ¾Ñ€Ñ–Ñ
            
        Returns:
            Dict Ğ· Ğ¿Ğ¾Ğ²Ğ½Ğ¸Ğ¼ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ğ¾Ğ¼
        """
        logger.info(f"Starting analysis of: {url}")
        
        # 1. Ğ’Ğ¸Ñ‚ÑĞ³ÑƒÑ”Ğ¼Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚
        content = self.extractor.extract_from_url(url)
        
        if not content['success']:
            return {
                'success': False,
                'error': content['error'],
                'url': url,
                'timestamp': datetime.now().isoformat()
            }
        
        # 2. ĞĞ½Ğ°Ğ»Ñ–Ğ·ÑƒÑ”Ğ¼Ğ¾ Ğ·Ğ° Veritas Protocol
        analysis = self.veritas.evaluate_integrity(
            text=content['text'],
            source=content['source']
        )
        
        # 3. Ğ¤Ğ¾Ñ€Ğ¼ÑƒÑ”Ğ¼Ğ¾ Ğ¿Ğ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ·Ğ²Ñ–Ñ‚
        full_report = {
            'success': True,
            'url': url,
            'timestamp': datetime.now().isoformat(),
            'content': {
                'title': content['title'],
                'source': content['source'],
                'text_length': len(content['text']),
                'text_preview': content['text'][:500] + '...' if len(content['text']) > 500 else content['text']
            },
            'veritas_analysis': {
                'language': analysis['language'],
                'entropy_index': analysis['entropy_index'],
                'reputation': analysis['reputation'],
                'status': analysis['status'],
                'verdict': analysis['verdict'],
                'intervention_required': analysis['intervention_required']
            },
            'recommendation': self._get_recommendation(analysis)
        }
        
        # 4. Ğ—Ğ±ĞµÑ€Ñ–Ğ³Ğ°Ñ”Ğ¼Ğ¾ Ğ² Ñ–ÑÑ‚Ğ¾Ñ€Ñ–Ñ
        if save_history:
            self.analysis_history.append(full_report)
        
        logger.info(f"Analysis complete: {analysis['status']}")
        return full_report
    
    def analyze_text(self, text: str, source: str = "Manual_Input") -> Dict:
        """
        ĞĞ½Ğ°Ğ»Ñ–Ğ· Ñ‚ĞµĞºÑÑ‚Ñƒ Ğ±ĞµĞ· Ğ²Ğ¸Ñ‚ÑĞ³ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ· URL
        
        Args:
            text: Ğ¢ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ
            source: ĞĞ°Ğ·Ğ²Ğ° Ğ´Ğ¶ĞµÑ€ĞµĞ»Ğ°
            
        Returns:
            Dict Ğ· Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ğ¾Ğ¼
        """
        analysis = self.veritas.evaluate_integrity(text=text, source=source)
        
        return {
            'success': True,
            'timestamp': datetime.now().isoformat(),
            'content': {
                'source': source,
                'text_length': len(text),
                'text_preview': text[:500] + '...' if len(text) > 500 else text
            },
            'veritas_analysis': analysis,
            'recommendation': self._get_recommendation(analysis)
        }
    
    def _get_recommendation(self, analysis: Dict) -> Dict:
        """
        Ğ“ĞµĞ½ĞµÑ€ÑƒÑ” Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ— Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ñ– Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ
        """
        entropy = analysis['entropy_index']
        status = analysis['status']
        language = analysis['language']
        
        recommendations = {
            'uk': {
                'TRUSTED': "âœ… Ğ”Ğ¶ĞµÑ€ĞµĞ»Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ° Ğ²Ğ²Ğ°Ğ¶Ğ°Ñ‚Ğ¸ Ğ½Ğ°Ğ´Ñ–Ğ¹Ğ½Ğ¸Ğ¼",
                'MONITORED': "âš ï¸ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒÑ”Ñ‚ÑŒÑÑ Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ° Ñ„Ğ°ĞºÑ‚Ñ–Ğ²",
                'WARNING': "ğŸ”¶ Ğ’Ğ¸ÑĞ¾ĞºĞ¸Ğ¹ Ñ€Ñ–Ğ²ĞµĞ½ÑŒ Ñ€Ğ¸Ñ‚Ğ¾Ñ€Ğ¸ĞºĞ¸. ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ¾Ğ±Ğ¾Ğ²'ÑĞ·ĞºĞ¾Ğ²Ğ¸Ğ¹",
                'REJECTED': "âŒ Ğ”Ğ¶ĞµÑ€ĞµĞ»Ğ¾ Ğ½Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒÑ”Ñ‚ÑŒÑÑ ÑĞº Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğµ"
            },
            'en': {
                'TRUSTED': "âœ… Source can be considered reliable",
                'MONITORED': "âš ï¸ Fact-checking recommended",
                'WARNING': "ğŸ”¶ High level of rhetoric. Critical analysis required",
                'REJECTED': "âŒ Source not recommended as primary"
            }
        }
        
        details = {
            'uk': {
                'action': 'Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ²Ğ°Ñ‚Ğ¸' if status in ['TRUSTED', 'MONITORED'] else 'Ğ£Ğ½Ğ¸ĞºĞ°Ñ‚Ğ¸',
                'trust_level': self._map_trust_level(entropy, 'uk'),
                'critical_thinking': 'ĞĞ¸Ğ·ÑŒĞºĞ¸Ğ¹' if entropy < 0.3 else 'Ğ’Ğ¸ÑĞ¾ĞºĞ¸Ğ¹'
            },
            'en': {
                'action': 'Use' if status in ['TRUSTED', 'MONITORED'] else 'Avoid',
                'trust_level': self._map_trust_level(entropy, 'en'),
                'critical_thinking': 'Low' if entropy < 0.3 else 'High'
            }
        }
        
        return {
            'message': recommendations[language][status],
            'action': details[language]['action'],
            'trust_level': details[language]['trust_level'],
            'critical_thinking_required': details[language]['critical_thinking']
        }
    
    def _map_trust_level(self, entropy: float, language: str) -> str:
        """ĞœĞ°Ğ¿Ğ¸Ñ‚ÑŒ entropy Ğ½Ğ° Ñ€Ñ–Ğ²ĞµĞ½ÑŒ Ğ´Ğ¾Ğ²Ñ–Ñ€Ğ¸"""
        levels = {
            'uk': ['Ğ”ÑƒĞ¶Ğµ Ğ²Ğ¸ÑĞ¾ĞºĞ¸Ğ¹', 'Ğ’Ğ¸ÑĞ¾ĞºĞ¸Ğ¹', 'Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹', 'ĞĞ¸Ğ·ÑŒĞºĞ¸Ğ¹', 'Ğ”ÑƒĞ¶Ğµ Ğ½Ğ¸Ğ·ÑŒĞºĞ¸Ğ¹'],
            'en': ['Very High', 'High', 'Medium', 'Low', 'Very Low']
        }
        
        if entropy < 0.2:
            return levels[language][0]
        elif entropy < 0.4:
            return levels[language][1]
        elif entropy < 0.6:
            return levels[language][2]
        elif entropy < 0.8:
            return levels[language][3]
        else:
            return levels[language][4]
    
    def get_source_reputation(self, source: str) -> float:
        """ĞŸĞ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” Ğ¿Ğ¾Ñ‚Ğ¾Ñ‡Ğ½Ñƒ Ñ€ĞµĞ¿ÑƒÑ‚Ğ°Ñ†Ñ–Ñ Ğ´Ğ¶ĞµÑ€ĞµĞ»Ğ°"""
        return self.veritas.reputation_registry.get(source, 0.5)
    
    def export_history(self, filename: str = None) -> str:
        """
        Ğ•ĞºÑĞ¿Ğ¾Ñ€Ñ‚ÑƒÑ” Ñ–ÑÑ‚Ğ¾Ñ€Ñ–Ñ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ Ğ² JSON
        
        Args:
            filename: ĞĞ°Ğ·Ğ²Ğ° Ñ„Ğ°Ğ¹Ğ»Ñƒ (Ğ¾Ğ¿Ñ†Ñ–Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
            
        Returns:
            Ğ¨Ğ»ÑÑ… Ğ´Ğ¾ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ
        """
        if filename is None:
            filename = f"veritas_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_history, f, ensure_ascii=False, indent=2)
        
        logger.info(f"History exported to: {filename}")
        return filename
    
    def generate_report(self, analysis: Dict) -> str:
        """
        Ğ“ĞµĞ½ĞµÑ€ÑƒÑ” Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¸Ğ¹ Ğ·Ğ²Ñ–Ñ‚
        
        Args:
            analysis: Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ
            
        Returns:
            Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¸Ğ¹ Ğ·Ğ²Ñ–Ñ‚
        """
        if not analysis['success']:
            return f"âŒ Error analyzing URL: {analysis.get('error', 'Unknown error')}"
        
        v = analysis['veritas_analysis']
        c = analysis['content']
        r = analysis['recommendation']
        
        lang = v['language']
        
        if lang == 'uk':
            report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           VERITAS PROTOCOL - ĞĞĞĞ›Ğ†Ğ— ĞĞĞ’Ğ˜ĞĞ˜                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“° Ğ—ĞĞ“ĞĞ›ĞĞ’ĞĞš: {c['title']}
ğŸŒ Ğ”Ğ–Ğ•Ğ Ğ•Ğ›Ğ: {c['source']}
ğŸ”— URL: {analysis['url']}
ğŸ“… Ğ§ĞĞ¡ ĞĞĞĞ›Ğ†Ğ—Ğ£: {analysis['timestamp']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ĞĞĞĞ›Ğ†Ğ— VERITAS PROTOCOL
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” Ğ†Ğ½Ğ´ĞµĞºÑ ĞµĞ½Ñ‚Ñ€Ğ¾Ğ¿Ñ–Ñ—: {v['entropy_index']:.3f}
ğŸ“ˆ Ğ ĞµĞ¿ÑƒÑ‚Ğ°Ñ†Ñ–Ñ Ğ´Ğ¶ĞµÑ€ĞµĞ»Ğ°: {v['reputation']:.2f}
ğŸ·ï¸  Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: {v['status']}
ğŸ’¬ Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚: {v['verdict']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ†Ğ‡
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{r['message']}

âœ“ Ğ”Ñ–Ñ: {r['action']}
âœ“ Ğ Ñ–Ğ²ĞµĞ½ÑŒ Ğ´Ğ¾Ğ²Ñ–Ñ€Ğ¸: {r['trust_level']}
âœ“ ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğµ Ğ¼Ğ¸ÑĞ»ĞµĞ½Ğ½Ñ: {r['critical_thinking_required']}

{'âš ï¸  ĞŸĞĞ¢Ğ Ğ†Ğ‘ĞĞ• Ğ’Ğ¢Ğ Ğ£Ğ§ĞĞĞĞ¯!' if v['intervention_required'] else ''}
            """
        else:  # English
            report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           VERITAS PROTOCOL - NEWS ANALYSIS                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“° TITLE: {c['title']}
ğŸŒ SOURCE: {c['source']}
ğŸ”— URL: {analysis['url']}
ğŸ“… ANALYSIS TIME: {analysis['timestamp']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š VERITAS PROTOCOL ANALYSIS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” Entropy Index: {v['entropy_index']:.3f}
ğŸ“ˆ Source Reputation: {v['reputation']:.2f}
ğŸ·ï¸  Status: {v['status']}
ğŸ’¬ Verdict: {v['verdict']}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ RECOMMENDATIONS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{r['message']}

âœ“ Action: {r['action']}
âœ“ Trust Level: {r['trust_level']}
âœ“ Critical Thinking Required: {r['critical_thinking_required']}

{'âš ï¸  INTERVENTION REQUIRED!' if v['intervention_required'] else ''}
            """
        
        return report.strip()


# Ğ¢ĞµÑÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ
if __name__ == "__main__":
    analyzer = NewsAnalyzer()
    
    # ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´ 1: ĞĞ½Ğ°Ğ»Ñ–Ğ· Ñ‚ĞµĞºÑÑ‚Ñƒ ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¾Ñ
    print("\n" + "="*70)
    print("TEST 1: Ukrainian Text Analysis")
    print("="*70)
    
    uk_text = "Ğ†ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡Ğ½Ğ¾ Ğ²Ğ°Ğ¶Ğ»Ğ¸Ğ²Ğ¾ ĞµÑ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ·Ğ°Ğ½ĞµĞ¿Ğ¾ĞºĞ¾Ñ—Ñ‚Ğ¸ÑÑ Ñ‡ĞµÑ€ĞµĞ· Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñƒ Ğ²Ñ‚Ñ€Ğ°Ñ‚Ñƒ Ğ´Ğ¾Ğ²Ñ–Ñ€Ğ¸ Ğ´Ğ¾ Ñ–Ğ½ÑÑ‚Ğ¸Ñ‚ÑƒÑ‚Ñ–Ğ²."
    result1 = analyzer.analyze_text(uk_text, "TestSource_UA")
    print(analyzer.generate_report(result1))
    
    # ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´ 2: ĞĞ½Ğ°Ğ»Ñ–Ğ· Ñ‚ĞµĞºÑÑ‚Ñƒ Ğ°Ğ½Ğ³Ğ»Ñ–Ğ¹ÑÑŒĞºĞ¾Ñ
    print("\n" + "="*70)
    print("TEST 2: English Text Analysis")
    print("="*70)
    
    en_text = "If the data equals zero, then the result consequently indicates a measurement error."
    result2 = analyzer.analyze_text(en_text, "TestSource_EN")
    print(analyzer.generate_report(result2))
    
    # ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´ 3: ĞĞ½Ğ°Ğ»Ñ–Ğ· URL (Ğ·Ğ°ĞºĞ¾Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²Ğ°Ğ½Ğ¾, Ğ±Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±ĞµĞ½ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹ URL)
    # print("\n" + "="*70)
    # print("TEST 3: URL Analysis")
    # print("="*70)
    # url = "https://www.bbc.com/news/world"
    # result3 = analyzer.analyze_url(url)
    # print(analyzer.generate_report(result3))
